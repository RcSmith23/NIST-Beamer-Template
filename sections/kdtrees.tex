
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             Background               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Introduction}

  \begin{itemize}
    \item A \kd tree is a data structure used for partitioning $k$-dimensional space
    \item At each node, a cluster of points is partitioned by a hyperplane and the resulting
      sets of points contained in the half-spaces are passed down to the child nodes
    \item Often, hyperplanes are kept orthogonal to one coordinate axis of the space
    \item Binary search trees are the one-dimensional versions of \kd trees
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Example: $k=1$}

  \begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{BST.pdf}
  \end{figure}
  
\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Example: $k=2$}
  
  \begin{figure}
    \centering
    \includegraphics[width=0.73\textwidth]{2dkdtree.pdf}
  \end{figure}

\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Example: $k=3$}
  
  \begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{3dkdtree.pdf}
  \end{figure}

\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Nearest neighbor search}

  \begin{enumerate}
    \item Given a point, $p$, rescursively move down the tree by computing the points orientation relative to the 
      hyperplane $t$ given by $p - \text{proj}_t(p)$
    \item At each node, compare the distance of the query point to the node's splitting point with the distance
      of the current nearest neighbor, if smaller, update nearest neighbor candidate
    \item Upon completion of recursive call, compare the distance of current nearest neighbor 
      candidate to the point with the distance to the hyperplane $\|p - \text{proj}_t(p)\|$; 
      if it is larger, search the other child branch of the node
  \end{enumerate}

\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Nanoflann}

  \begin{itemize}
    \item Header-only C++ \kd tree implementation that supports k-nearest neighbor and radius search with 
      L1 or L2 metric
    \item Utilizes curiously recurring template pattern and inlined functions for high performance
    \item Used for nearest neighbor search in our ZENO/Walk-on-Spheres implementation 
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             Limitations              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Limitations of trees}

  \begin{itemize}
    \item Memory access pattern when searching tree is unpredictable
      \begin{itemize}
        \item Impossible to align contiguous blocks that have temporal locality
        \item Difficult to prefetch memory
      \end{itemize}
    \item Spatially close points can end up far away in the tree (e.g., neighboring points divided by 
      root's hyperplane)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{GPU restrictions}

  \begin{itemize}
    \item In the best case, when the tree is balanced, the height is $O(\log n)$
      \begin{itemize}
        \item Each search query will require at least $O(\log n )$ pointer dereferences - very costly on graphics 
          hardware
      \end{itemize}
    \item At each node we can only look ahead to one additional subspace of points
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\kd trees}
  \framesubtitle{Height and its memory limitations}

  \begin{columns}[T]
    \begin{column}{.5\textwidth}
      \begin{block}{}%
        {\color{white} Costly edge cases lead to large variance in search dereferences 
          and time}
      \end{block}
    \end{column}
    \begin{column}{.5\textwidth}
      \begin{block}{}
        \includegraphics[width=0.85\textwidth]{nn_adjaceny_simple.pdf}
      \end{block}
    \end{column}
  \end{columns}
\end{frame}
